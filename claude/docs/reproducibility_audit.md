# ワークフロー再現性 監査レポート

初版: 2026-02-18
更新: 2026-02-18（バグ修正完了・抽出拡大後）
対象: claude/src 配下のキャプチャ・ワークフロー・再生システム全体

---

## 結論（先に）

**Visionフォールバックのバグ修正完了。ただし実効再現率は依然として推定80-90%にとどまる。**

前回指摘:
- ~~修正すべきバグが1件ある（ANTHROPIC_API_KEY 未対応）~~ → **修正済み（コミット 6df0e36）**
- スクリーンショットは全ステップに100%付いている → **変わらず**
- Vision フォールバック（AIによる画像認識）のコードは実装済み → **Anthropic対応済み**

今回追加:
- ワークフロー数が 420 → **616件**に拡大（1,154セグメント中415を分析）
- 対応アプリが 24 → **25種**に増加
- 全616ワークフローのうち **98.4%（607件）がパラメータ化済み**（再利用可能）

---

## 1. 要素識別の仕組み（action_player.py）

再生時の要素検索は以下の優先順位で行われる:

```
1. identifier 一致     → 最も確実（アプリ固有の内部ID）
2. value 一致          → 確実（テキストフィールドの値など）
3. description 一致    → 確実（アクセシビリティの説明文）
4. title + role 一致   → やや確実（"再読み込み" + AXButton など）
5. アプリ全体検索      → ウィンドウ位置変更に対応（上記4条件で全要素再帰検索）
6. 座標フォールバック   → 再現性なし（記録時の生座標をそのまま使用）
7. Vision フォールバック → AIがスクリーンショットから要素位置を推定
```

## 2. キャプチャデータの品質（5,909件分析）

| 要素情報 | 前回（4,693件） | 今回（5,909件） |
|---------|---------------|---------------|
| 意味のある名前 | 1,494 (31%) | ≒同等比率 |
| identifier あり | 149 (3%) | ≒同等比率 |
| value あり | 810 (17%) | ≒同等比率 |
| description あり | 433 (9%) | ≒同等比率 |
| **汎用名のみ（AXGroup等）** | **2,780 (59%)** | **≒同等比率** |

※ 新規キャプチャ1,216件追加（主にCursor/Codex/Chrome/Gemini）。比率に大きな変動なし。

### 問題（変わらず）
- **59%のキャプチャは「AXGroup」「AXImage」としか記録されていない**
- macOSのアクセシビリティAPIの限界。Electron系アプリ（Chrome/Slack/Discord等）で顕著
- この59%は座標フォールバック→Vision フォールバックの対象

## 3. ワークフロー抽出結果（AI分析）

### 抽出統計

| 項目 | 前回（324/877） | 今回（415/1,154） |
|------|---------------|------------------|
| 分析済みセグメント | 324 | 415 |
| 全セグメント | 877 | 1,154 |
| 新規ワークフロー | 192 | 203 |
| 重複スキップ | — | 32 |
| confidence更新 | — | 8 |
| **ワークフロー総数** | **420** | **616** |
| エラー率 | 0% | 0% |

### アプリ別ワークフロー数（上位15）

| アプリ | 件数 | 主な操作内容 |
|-------|------|------------|
| Cursor | 205 | コード編集・ファイル操作・画像コピペ |
| Google Chrome | 117 | タブ切替・ページ操作・検索 |
| Ghostty | 40 | ターミナルコマンド実行・スクリプト操作 |
| Slack | 28 | チャンネル切替・メッセージ送信 |
| Google Gemini | 27 | AI対話・プロンプト入力 |
| Discord | 26 | サーバー操作・チャンネル移動 |
| Codex | 26 | プロジェクト管理・コード操作 |
| Finder | 25 | ファイル管理・フォルダ操作 |
| NotebookLM | 20 | ノート管理・AI分析 |
| Claude | 19 | AI対話・プロンプト操作 |
| LINE | 18 | メッセージ送受信 |
| Gmail | 14 | メール操作 |
| Google カレンダー | 11 | スケジュール管理 |
| Linear | 11 | タスク管理・Issue操作 |
| その他11アプリ | 29 | テキストエディット, ChatGPT, Code 等 |
| **合計 25アプリ** | **616** | |

### ワークフロー品質

| confidence帯 | 件数 | 割合 |
|-------------|------|------|
| 高 (≥0.8) | 60 | 9.7% |
| 中 (0.6-0.8) | 521 | 84.6% |
| 低 (<0.6) | 35 | 5.7% |
| **パラメータ化済み** | **607** | **98.4%** |

## 4. ワークフロー内ステップの再現性（3,639ステップ）

| 分類 | 件数 | 割合 | 再現方法 |
|------|------|------|---------|
| AXUIElementで特定可能 | ≒1,674 | **≒46%** | identifier/value/description/title+roleで検索 |
| 座標フォールバック必要 | ≒1,929 | **≒53%** | Vision AIフォールバック（修正済み） |
| スクリーンショット付き | 3,639 | **100%** | Vision AIによる画像認識が可能 |
| テキスト入力 | 別途 | — | 座標不問で再現可能 |

## 5. Vision フォールバックの現状

### 仕組み
座標フォールバックになった場合、action_player.py がスクリーンショットをAI（Vision API）に送信し、要素の現在位置を推定する。

```python
# action_player.py L574
if method == "coordinate_fallback":
    vision_coords = self._find_element_with_vision_fallback(step, step.screenshot_path)
    if vision_coords is not None:
        x, y = vision_coords
        result["method"] = "vision_fallback"
```

### ~~バグ: ANTHROPIC_API_KEY 未対応~~ → 修正済み

**修正内容（コミット 6df0e36）:**

1. **APIキー存在チェック**（L485）:
```python
# 修正前
api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("OPENAI_API_KEY")

# 修正後
api_key = (os.environ.get("ANTHROPIC_API_KEY")
           or os.environ.get("GEMINI_API_KEY")
           or os.environ.get("OPENAI_API_KEY"))
```

2. **AIClient初期化**（L526）:
```python
# 修正前: gemini/openai のみ分岐
client = AIClient(provider=config.ai_provider,
    model=config.gemini_model if config.ai_provider == "gemini" else config.openai_model)

# 修正後: 全プロバイダー対応
model_map = {
    "anthropic": config.anthropic_model,
    "gemini": config.gemini_model,
    "openai": config.openai_model,
}
client = AIClient(provider=config.ai_provider,
    model=model_map.get(config.ai_provider))
```

## 6. OCR は使われているか？

**使われていない。** 現在のシステムは以下の2つの方法のみ:

1. **macOS Accessibility API（AXUIElement）** — UIツリーから要素名・ロール・ID等を取得
2. **AI Vision API** — スクリーンショットを画像として送信し、要素位置を推定（OCRではなく画像認識）

OCR（文字認識）は一切行われていない。

## 7. 再現性を高めるための改善案

### ~~即座に対応可能（バグ修正レベル）~~ → 完了
1. ~~Vision フォールバックの ANTHROPIC_API_KEY 対応~~ → **修正済み**
2. ~~AIClient初期化のprovider分岐修正~~ → **修正済み**

### 短期的改善（未着手）
3. **キャプチャ時にOCRを実行** — AXGroupしか取れない要素に対して、スクリーンショットから周辺テキストを抽出して記録。再生時に同じテキストを画面上で検索
4. **スクリーンショット差分マッチング** — 記録時のスクリーンショットの該当領域を切り出し、再生時に現在の画面でテンプレートマッチング

### 中期的改善（未着手）
5. **Computer Use API の活用** — Anthropic の Computer Use 機能で、「このスクリーンショットの中で○○をクリックして」と直接指示
6. **要素のコンテキスト情報強化** — AXGroup の親要素・兄弟要素のtitle/valueも記録し、相対位置で特定

## 8. 未完了の抽出作業

| 項目 | 状況 |
|------|------|
| 全セグメント | 1,154 |
| 分析済み | 415 (36%) |
| **未分析** | **739 (64%)** |
| 推定追加ワークフロー | ≒350件 |
| 推定追加APIコスト | ≒$2.2（Haiku 4.5） |

残り739セグメントの抽出を再開すれば、ワークフロー総数は推定950-1,000件に達する。

## 9. 現時点の再現性まとめ

```
全ステップ: 3,639件（616ワークフロー, 25アプリ）
├── AXUIElement で確実に再現可能: ≒1,674件 (46%)
├── 座標フォールバック → Vision AI: ≒1,929件 (53%)
│   ├── Vision AI 実装済み + バグ修正済み（Anthropic対応）
│   ├── スクリーンショット100%完備
│   └── Vision AI で救済可能: 推定70-80%
└── テキスト入力（座標不問で再現可能）: 別途存在
```

**修正前の実効再現率: 約46%**
**Vision バグ修正後の推定再現率: 約80-90%**

---

## 変更履歴

| 日付 | 変更内容 |
|------|---------|
| 2026-02-18（初版） | 再現性監査実施。Visionバグ発見。4,693件/2,276ステップ分析 |
| 2026-02-18（更新） | Visionバグ修正完了（6df0e36）。抽出拡大（5,909件/3,639ステップ/616ワークフロー）。アプリ別・品質統計追加 |
